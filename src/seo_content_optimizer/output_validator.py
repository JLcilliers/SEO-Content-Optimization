"""
Output validation for LLM-generated content.

This module provides post-generation safety checks to ensure LLM outputs
don't contain blocked industry terms or off-topic content that wasn't
in the original. This is a CRITICAL defense-in-depth layer that catches
any hallucinations or prompt injection that bypassed earlier filters.

The validation works by:
1. Detecting blocked industry terms in LLM output
2. Checking if those terms were present in the original content
3. Flagging or sanitizing content that introduces off-topic industries
"""

import re
from dataclasses import dataclass
from typing import Optional


# HIGH-RISK INDUSTRY TERMS - These should NEVER be introduced by the optimizer
# These are the same as in keyword_filter.py but used for output validation
BLOCKED_TERMS = {
    # Cannabis/Hemp - HIGHEST PRIORITY
    "cannabis", "marijuana", "hemp", "cbd", "thc", "dispensary",
    "cannabidiol", "cannabis-infused", "hemp-derived", "marijuana dispensary",

    # Adult/Gambling/Vice
    "adult", "gambling", "casino", "betting", "poker", "lottery",
    "escort", "porn", "xxx", "adult entertainment",

    # Tobacco/Vape
    "tobacco", "vape", "vaping", "e-cigarette", "e-cig", "nicotine",

    # Firearms/Weapons
    "firearms", "guns", "ammunition", "weapons", "firearm",
    "gun shop", "gun store", "ammo",

    # Alcohol
    "alcohol", "liquor", "wine", "beer", "brewery", "distillery",
    "bar", "tavern", "pub", "liquor store",

    # Spammed Service Verticals
    "hair salon", "nail salon", "barbershop", "spa", "massage",
    "massage therapy", "massage parlor",
    "tattoo", "tattoo parlor", "piercing", "body piercing",
    "tanning", "tanning salon", "beauty salon", "salon",
    "restaurant", "food truck", "cafe", "coffee shop", "bakery",
    "gym", "fitness center", "yoga studio", "pilates", "crossfit",
    "auto repair", "car wash", "mechanic", "auto body",
    "laundromat", "dry cleaning", "laundry",
    "pet grooming", "veterinary", "vet clinic", "pet store",
    "daycare", "childcare", "preschool",
    "florist", "flower shop",
    "convenience store", "pawn shop", "pawnshop",

    # High-Risk Merchant Terms (commonly injected wrongly)
    "high risk merchant", "high-risk merchant", "high risk processing",
    "high-risk processing", "high risk payment", "high-risk payment",
    "merchant account", "merchant services",

    # Crypto/Forex
    "forex", "cryptocurrency", "crypto", "bitcoin", "nft",
    "crypto exchange", "bitcoin payment",

    # Payday/Debt
    "payday loan", "cash advance", "debt collection",
    "payday lender", "title loan",

    # Healthcare (regulated, shouldn't be added)
    "pharmacy", "medical", "healthcare", "doctor", "clinic",
    "dental", "dentist", "chiropractor", "therapy",
    "telehealth", "telemedicine", "prescription",
}

# Single word high-priority blocklist - individual words that are ALWAYS blocked
# These are the most aggressively blocked terms
SINGLE_WORD_BLOCKLIST = {
    "hemp", "cbd", "cannabis", "marijuana", "thc", "dispensary",
    "salon", "spa", "massage", "tattoo",
    "casino", "gambling", "betting",
    "firearm", "firearms", "guns", "weapons",
    "escort", "porn", "adult",
    "vape", "vaping",
}


@dataclass
class ValidationResult:
    """Result of content validation."""
    is_valid: bool
    violations: list[str]
    sanitized_content: Optional[str] = None
    original_content: str = ""

    @property
    def has_violations(self) -> bool:
        return len(self.violations) > 0


def _term_in_text(term: str, text: str) -> bool:
    """Check if a term appears as a whole word/phrase in text."""
    pattern = r'\b' + re.escape(term) + r'\b'
    return bool(re.search(pattern, text, re.IGNORECASE))


def find_blocked_terms(text: str) -> list[str]:
    """
    Find all blocked terms present in text.

    Args:
        text: Text to scan for blocked terms.

    Returns:
        List of blocked terms found (lowercased).
    """
    text_lower = text.lower()
    found = []

    # Check single-word blocklist first (highest priority)
    for term in SINGLE_WORD_BLOCKLIST:
        if _term_in_text(term, text_lower):
            found.append(term)

    # Check full blocked terms list
    for term in BLOCKED_TERMS:
        if term not in SINGLE_WORD_BLOCKLIST and _term_in_text(term, text_lower):
            found.append(term)

    return list(set(found))  # Deduplicate


def validate_output(
    llm_output: str,
    original_content: str,
    context: str = "content",
) -> ValidationResult:
    """
    Validate LLM output for blocked industry terms.

    This is the main validation function. It checks if the LLM output
    contains any blocked terms that weren't in the original content.

    Args:
        llm_output: The content generated by the LLM.
        original_content: The original content before optimization.
        context: Description of what's being validated (for error messages).

    Returns:
        ValidationResult with validity status and any violations found.
    """
    if not llm_output:
        return ValidationResult(
            is_valid=True,
            violations=[],
            original_content=original_content,
        )

    # Find blocked terms in the LLM output
    output_blocked = find_blocked_terms(llm_output)

    if not output_blocked:
        # No blocked terms found - output is valid
        return ValidationResult(
            is_valid=True,
            violations=[],
            original_content=original_content,
        )

    # Check which blocked terms are NEW (not in original)
    original_blocked = find_blocked_terms(original_content) if original_content else []
    original_blocked_set = set(original_blocked)

    # Violations are terms in output that weren't in original
    violations = [term for term in output_blocked if term not in original_blocked_set]

    if not violations:
        # All blocked terms were already in original - this is allowed
        return ValidationResult(
            is_valid=True,
            violations=[],
            original_content=original_content,
        )

    # We have violations - output introduced blocked terms
    return ValidationResult(
        is_valid=False,
        violations=violations,
        original_content=original_content,
    )


def validate_and_fallback(
    llm_output: str,
    original_content: str,
    context: str = "content",
) -> tuple[str, ValidationResult]:
    """
    Validate LLM output and fall back to original if invalid.

    This is the safe wrapper that ensures we never return content
    with newly introduced blocked terms.

    Args:
        llm_output: The content generated by the LLM.
        original_content: The original content before optimization.
        context: Description of what's being validated.

    Returns:
        Tuple of (safe_content, validation_result).
        If validation fails, safe_content will be the original.
    """
    result = validate_output(llm_output, original_content, context)

    if result.is_valid:
        return llm_output, result

    # Validation failed - fall back to original content
    # Log the violation for debugging (in production, this could be sent to monitoring)
    result.sanitized_content = original_content
    return original_content, result


def validate_faq_items(
    faq_items: list[dict[str, str]],
    original_content: str,
) -> tuple[list[dict[str, str]], list[ValidationResult]]:
    """
    Validate FAQ items and filter out any with blocked terms.

    Args:
        faq_items: List of FAQ dicts with 'question' and 'answer' keys.
        original_content: The original page content.

    Returns:
        Tuple of (valid_faqs, all_validation_results).
    """
    valid_faqs = []
    all_results = []

    for i, faq in enumerate(faq_items):
        question = faq.get("question", "")
        answer = faq.get("answer", "")
        combined = f"{question} {answer}"

        result = validate_output(combined, original_content, f"FAQ #{i+1}")
        all_results.append(result)

        if result.is_valid:
            valid_faqs.append(faq)
        # If invalid, we simply skip this FAQ item

    return valid_faqs, all_results


def get_violation_summary(results: list[ValidationResult]) -> dict:
    """
    Generate a summary of validation violations.

    Args:
        results: List of ValidationResult objects.

    Returns:
        Dict with summary statistics.
    """
    total = len(results)
    valid = sum(1 for r in results if r.is_valid)
    invalid = total - valid

    all_violations = []
    for r in results:
        all_violations.extend(r.violations)

    return {
        "total_checked": total,
        "valid_count": valid,
        "invalid_count": invalid,
        "unique_violations": list(set(all_violations)),
        "violation_frequency": {v: all_violations.count(v) for v in set(all_violations)},
    }


# =============================================================================
# CONTENT PRESERVATION VALIDATION
# =============================================================================
# These functions ensure that original content is never deleted during
# optimization. The tool should only ADD content, never remove it.


def validate_content_preservation(
    original: str,
    optimized: str,
    min_preservation_ratio: float = 0.85,
    context: str = "content",
) -> tuple[bool, str]:
    """
    Validate that optimized content preserves the original content.

    This is a CRITICAL check to ensure optimization is ADDITIVE only.
    Content should grow (with keyword insertions), never shrink.

    Args:
        original: Original content before optimization.
        optimized: Content after optimization.
        min_preservation_ratio: Minimum ratio of original length that must be preserved.
            Default 0.85 allows for minor sentence rewording while catching deletions.
        context: Description for error messages.

    Returns:
        Tuple of (is_valid, error_message).
        is_valid is True if content is preserved, False if significant deletion detected.
    """
    if not original:
        return True, ""

    if not optimized:
        return False, f"CRITICAL: {context} was completely deleted (empty output)"

    original_len = len(original.strip())
    optimized_len = len(optimized.strip())

    # Optimized should be >= original (we're adding, not removing)
    if optimized_len >= original_len:
        return True, ""

    # Calculate preservation ratio
    ratio = optimized_len / original_len if original_len > 0 else 0

    if ratio < min_preservation_ratio:
        deletion_pct = (1 - ratio) * 100
        return False, (
            f"CRITICAL: {context} content deleted - "
            f"original: {original_len} chars, optimized: {optimized_len} chars "
            f"({deletion_pct:.1f}% deleted)"
        )

    return True, ""


def validate_block_preservation(
    original_blocks: list,
    optimized_blocks: list,
    context: str = "body",
) -> tuple[bool, str]:
    """
    Validate that all original blocks are preserved in output.

    Args:
        original_blocks: Original content blocks.
        optimized_blocks: Blocks after optimization.
        context: Description for error messages.

    Returns:
        Tuple of (is_valid, error_message).
    """
    if not original_blocks:
        return True, ""

    original_count = len(original_blocks)
    optimized_count = len(optimized_blocks)

    # We should have at least as many blocks (can add, not remove)
    if optimized_count < original_count:
        return False, (
            f"CRITICAL: {context} blocks deleted - "
            f"original: {original_count} blocks, optimized: {optimized_count} blocks"
        )

    return True, ""


def validate_and_preserve(
    llm_output: str,
    original_content: str,
    context: str = "content",
    min_preservation_ratio: float = 0.85,
) -> tuple[str, bool, str]:
    """
    Validate LLM output and fall back to original if content was deleted.

    This combines blocked term validation with content preservation validation.
    If either check fails, returns the original content.

    Args:
        llm_output: The content generated by the LLM.
        original_content: The original content before optimization.
        context: Description for error messages.
        min_preservation_ratio: Minimum ratio of original content to preserve.

    Returns:
        Tuple of (safe_content, is_valid, error_message).
        safe_content will be original_content if validation fails.
    """
    # First check for blocked terms
    term_result = validate_output(llm_output, original_content, context)
    if not term_result.is_valid:
        return original_content, False, f"Blocked terms: {term_result.violations}"

    # Then check content preservation
    is_preserved, preservation_error = validate_content_preservation(
        original_content, llm_output, min_preservation_ratio, context
    )
    if not is_preserved:
        return original_content, False, preservation_error

    return llm_output, True, ""
